---
title: "Homework 2"
output: html_document
---

Ruicheng Yang, ry2539, p8105

# Problem 1

```{r setup}
library(tidyverse)
library(readxl)
```

```{r read dataframes}

#read dataframes using csv funtion#

pols_df = read_csv("./fivethirtyeight_datasets/fivethirtyeight_datasets/pols-month.csv")
snp_df = read_csv("./fivethirtyeight_datasets/fivethirtyeight_datasets/snp.csv")
unemployment_df = read_csv("./fivethirtyeight_datasets/fivethirtyeight_datasets/unemployment.csv")
```

```{r clean_pols_dataframe}

#separate mon variabe in dataframe into year, month, day#

separate_pols_df =
  
  separate(pols_df, mon, into = c("Year", "month", "day"), sep = "-")

#change variables above into integer variables#

integer_pols_df =
  mutate(separate_pols_df,
         Year = strtoi(Year),
         month = strtoi(month),
         day = strtoi(day))

#Turn month values 1, 2, 3,... to january, february, march, etc.#

month_name_pols_df = 
  mutate(integer_pols_df, month = month.abb[month])

#Create the president variable#

president_pols_df = mutate(month_name_pols_df, 
                           president = case_when(
                             prez_dem == 1 ~ "gop",
                             prez_gop == 1 ~ "dem"
                           ))

#Remove the unnecessary variables day, prezdem, prezgop#

clean_pols_df = select(president_pols_df, -day, -prez_dem, -prez_gop)

```

```{r clean_snp_dataframe}

#separate mon variable in dataframe into year, month, day#

separate_snp_df =
  
  separate(snp_df, date, into = c("month", "day", "year"), sep = "/")

#change variables above into integer variables#

integer_snp_df =
  mutate(separate_snp_df,
         month = strtoi(month),
         day = strtoi(day))

#Turn month values 1, 2, 3,... to january, february, march, etc.#

month_name_snp_df = 
  mutate(integer_snp_df, month = month.abb[month])

#Turn the years 15, 16, 50, to years 2015, 2016, 1950, etc.#

year_name_snp_df = mutate(month_name_snp_df, Year = case_when(
  year <= 15 ~ paste0("20", year),
  year >= 50 ~ paste0("19", year)
))

#remove the day and original year variable since now we have the Year variable#

clean_snp_df = select(year_name_snp_df, -day, -year)

#Make sure Year and month are leading variables and change the Year variable into an integer variable#
string_to_integer_snp_df = mutate(clean_snp_df, Year = strtoi(Year))
arranged_snp_df = select(string_to_integer_snp_df, Year, month, close)

```

```{r pivot_unemployment_dataframe}

#pivot the dataframe into a longer form, with Year, Month, and unemployment rate as our three columns#

pivot_unemployment_df = 
  pivot_longer(
    unemployment_df, Jan:Dec, 
    names_to = "month",
    values_to = "unemployment_rate"
  )

clean_unemployment_df = arrange(pivot_unemployment_df, Year, month)
```

```{r merged_dataframes}

#Firs left_join snp dataframe and clean_pols dataframe, then merge that dataframe with unemployment dataframe#

first_merged_df = left_join(clean_pols_df , arranged_snp_df, by = c("Year", "month"))
final_merged_df = left_join(clean_unemployment_df, first_merged_df, by = c("Year", "month"))

final_merged_df
```

The pols data frame shows the number of republican and democrat candidates in the president, governor, senator, and representative positions for each year from 1948 to 2015. The snp data frame shows the close price of the S&P 500 for each given date from 1950 to 2015. Finally, the unemployment data frame tells us the unemployment rate for each month from 1948 to 2015. The final data set has 816 rows and 11 columns. The years range from 1948 to 2015. Some of the key variables include the unemployment rate, the year and month, the S&P close price, and whether the president at said time was a republican or democrat.

# Problem 2

```{r}

#Read the excel datafiles using read_excel#

mr_trash_wheel_df = read_excel("./fivethirtyeight_datasets/202509 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N710")

#Omit the rows without a dumpster value#

mr_trash_wheel_omit_df = drop_na(mr_trash_wheel_df, Dumpster)

#Change the sports balls data into an integer variable and round it#

almost_mr_trash_wheel_df = mutate(mr_trash_wheel_omit_df, `Sports Balls` = as.integer(round(`Sports Balls`, 0)))

#Change variable of Year to an integer so that we can merge the data sheets#

without_name_mr_trash_wheel_df = mutate(almost_mr_trash_wheel_df, Year = as.integer(Year))

#Add a new variable Sheet and assign the variable as "Mr. Trash Wheel"#

clean_mr_trash_wheel_df = mutate(without_name_mr_trash_wheel_df, Sheet = "Mr. Trash Wheel")
```

```{r}

#Read the excel datafiles using read_excel#

professor_trash_wheel_df = read_excel("./fivethirtyeight_datasets/202509 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M135")

#Omit the rows without a dumpster value#

professor_trash_wheel_omit_df = drop_na(professor_trash_wheel_df, Dumpster)

#Change variable of Year to an integer so that we can merge the data sheets#

without_professor_trash_wheel_df = mutate(professor_trash_wheel_omit_df, Year = as.integer(Year))

#Add a new variable Sheet and assign the variable as "Professor Trash Wheel"#

clean_professor_trash_wheel_df = mutate(without_professor_trash_wheel_df, Sheet = "Professor Trash Wheel", `Sports Balls` = NA)
```

```{r}

#Read the excel datafiles using read_excel#

Gwynnda_trash_wheel_df = read_excel("./fivethirtyeight_datasets/202509 Trash Wheel Collection Data.xlsx", sheet = "Gwynns Falls Trash Wheel", range = "A2:L352")

#Omit the rows without a dumpster value#

Gwynnda_trash_wheel_omit_df = drop_na(Gwynnda_trash_wheel_df, Dumpster)

#Change variable of Year to an integer so that we can merge the data sheets#

without_Gwynnda_trash_wheel_df = mutate(Gwynnda_trash_wheel_omit_df, Year = as.integer(Year))

#Add a new variable Sheet and assign the variable as "Professor Trash Wheel"#

clean_Gwynnda_trash_wheel_df = mutate(without_Gwynnda_trash_wheel_df, Sheet = "Gwynns Falls Trash Wheel", `Sports Balls` = NA, `Glass Bottles` = NA)
```

```{r}
#Use bind rows to observe all the data points from all 3 sheets#

merged_data_trash_wheel_1 = bind_rows(clean_mr_trash_wheel_df, clean_professor_trash_wheel_df, clean_Gwynnda_trash_wheel_df)

#Make sure to put sheet first as a variable so we know which sheet each observation comes from#

merged_data_trash_wheel_final = select(merged_data_trash_wheel_1, Sheet, everything())

merged_data_trash_wheel_final
```

In total, we have 1,188 observations from Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. It is important to note that Mr. Trash Wheel has much more dumpsters observed than the other two data frames. It is also notable that Gwynnda lacks data on glass bottles and sports balls, while Professor Trash Wheel lacks data on sports balls altogether. Regardless, we can still examine the total weight of trash collected for both data sets.

For example, in the July of 2023, Gwynnda Trash Wheel has collected a total of 20.02 tons of trash from dumpster 155 to 160. Meanwhile, in the month of september of 2023, Professor Trash Wheel collected a total of 4.14 tons of trash from 2 dumpsters. As a subset of this data, these two dumptsers collected 25 cubic yards of said trash. 

Other variables like sports balls and homes powered are also included in the dataset. For Mr. Trash Wheel, across all dumpsters from May 2014 to July 2025, a total of `r sum(merged_data_trash_wheel_final$"Weight (tons)"[708:839])` tons of trash was collected and about 30,020 homes were powered. Meanwhile, for Gwynnda in the June of 2022, the total number of cigarette butts collected was `r sum(merged_data_trash_wheel_final$"Cigarette Butts"[914:926])`.

# Problem 3

```{r}

#Read the zillow rental price data file#

zillow_price_df = read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")

#Have a new data variable as ZipCode from the regionname variable#

zillow_price_zip_variation_df = mutate(zillow_price_df, ZipCode = RegionName)

#Clean the data and eliminate StateName, RegionName, RegionType, which are unnecessary data variables#

zillow_clean_price_df = select(zillow_price_zip_variation_df, -`StateName`, -RegionName, -RegionType)
```

```{r}

#Read the zillow properties data file#

zillow_df = read_csv("./zillow_data/Zip Codes.csv")

#Mutate the CountyName variable from "Bronx" to "Bronx County"#

zillow_county_variation_df = mutate(zillow_df, CountyName = paste(County, "County"))

#Eliminate varibles such as State FIPS, County FIPS, and County#

zillow_clean_df = select(zillow_county_variation_df, -`State FIPS`, -`County FIPS`, -County)
```

```{r}

#Merge the two datasets into a single tidy dataset#

first_single_zillow_df = left_join(zillow_clean_df, zillow_clean_price_df)
first_clean_single_zillow_df = arrange(first_single_zillow_df, RegionID)

#Count the unique zip codes and neighborhoods present in this dataset#

unique_zip_codes = length(unique(first_clean_single_zillow_df$ZipCode))
unique_neighborhoods = length(unique(first_clean_single_zillow_df$Neighborhood))

print(unique_zip_codes)
print(unique_neighborhoods)

first_clean_single_zillow_df

```

```{r}

#Merge the two dataframes by only keeping the zip codes in the rental price dataframe#

single_zillow_df = left_join(zillow_clean_price_df, zillow_clean_df)

#Include a new variable with rental difference between 2021 vs 2020#

rental_price_zillow_df = mutate(single_zillow_df, `Rental Difference 2021 vs 2020` = `2021-01-31` - `2020-01-31`)

#Rank the rows of the single dataframe according to the rental differences#

clean_zillow_single_df = arrange(rental_price_zillow_df, `Rental Difference 2021 vs 2020`)

#Visualize an arranged dataframe#

arranged_zillow_df = select(clean_zillow_single_df, `RegionID`, SizeRank, ZipCode, State, City, CountyName, `County Code`, Neighborhood, Metro, `Rental Difference 2021 vs 2020`, `2020-01-31`, `2021-01-31`)

arranged_zillow_df

#Arrange dataframe with zipcode, neighborhood, and rental difference as leading columns, then slice off the dataframe and create a table with top 10 biggest drops#

dataframe_price_drop = select(arranged_zillow_df, ZipCode,Neighborhood, `Rental Difference 2021 vs 2020`)
price_drop_table = slice_head(dataframe_price_drop, n= 10)


print(price_drop_table)
```


There are a total of 322 observations after our single tidy data set. Overall, there are 320 unique zip codes in total and 43 unique neighborhoods. However, when we are trying to see how many zip codes were excluded from the rental price data, we see that most of the properties excluded are located in New York County, a.k.a. Manhattan. 

Seeing that these properties are in Manhattan, they may have been excluded because these properties are occupied by businesses. Other properties in this area do not have a rental price, but rather have a high-ranged price of millions, in comparison to the rental price of other properties in upper Manhattan.

For most of these properties, their rental price dropped in 2021 in comparison to their price in 2020. Notably, the 10 biggest drops in the rental prices are in lower Manhattan. This could be because the demand for these properties in 2021 decreased, therefore decreasing their rental price.
